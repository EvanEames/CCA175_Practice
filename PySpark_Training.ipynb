{"cells":[{"cell_type":"markdown","source":["### CLOUDERA CCA175 - PRACTISE TEST"],"metadata":{}},{"cell_type":"markdown","source":["### Question 0: Load practise dataset and manually define schema\nThe dataset is stored here: /databricks-datasets/Rdatasets/data-001/csv/ggplot2/diamonds.csv\n\nRead it is as a csv, but include option(\"inferSchema\",\"false\") and manually define the schema. The Schema should have the form:\n\n* index: integer (nullable = true)\n* carat: double (nullable = true)\n* cut: string (nullable = true)\n* color: string (nullable = true)\n* clarity: string (nullable = true)\n* depth: double (nullable = true)\n* table: double (nullable = true)\n* price: integer (nullable = true)\n* x: double (nullable = true)\n* y: double (nullable = true)\n* z: double (nullable = true)"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### Question 1 - Count how many diamonds are of each colour"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Question 2 -  Make a new row which consists of the first letter of 'cut' followed by the 'color', with a space in between the two\nSo for example if Cut = Ideal and Color = E, there should be a new column called 'CutColor' with 'I  E'.\n\nAlso, replace the Cut and Color columns by the CutColor column."],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["### Question 3 - Create two tables and then re-join them\nDefine D1 to be a table with just the index and carat. Define D2 to be just the index and the price. Then rejoin the two of them to get a table with index, carat, and price."],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["### Question 4 - Multiply the dimensions to calculate volume, and then sort the entries by descending volume (with 2 decimal places).\nTips: Look into the 'round' function, which can be used inside DF.select."],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### Question 5 - Read in the Table as an RDD, Remove the Header, and Turn it into a DF\nYou must manually define a schema using StructType, which is read in when creating the DF"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["### Question 6 - Reading in the Table as an DF, Output the Average Price Per Cut"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["### Question 7 - Reading in the Table as an RDD, Output the Average Price Per Cut"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["### Really Important Additional Stuff!"],"metadata":{}},{"cell_type":"markdown","source":["#### The first two questions require you to execute 1 sqoop import and 1 sqoop export. Memorize these commands more or less exactly. But note that the format may change slightly (for example the --where condition may be slightly different). Be sure the directory is correct too."],"metadata":{}},{"cell_type":"code","source":["sqoop import --connect jdbc:mysql://gateway/problem1 --username cloudera --password cloudera --table customers --where \"city='CA'\" --fields-terminated-by\",\" --as-textFile --verbose\nsqoop sqoop export --table solution --connect jdbc:mysql://gateway/problem2 --username cloudera --password cloudera --export-dir '/user/cert/problem2/data/customer' --update-mode allowinsert --verbose"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["#### The remaining 7 quesitons all require you to read in some data, manipulate it, and save it back to a directory. Be extrememly careful regarding the file type you write to. You may have to write to csv, json, parquet, or a text file. In general, you just include .format('json') in the save function, but be careful as to save to a text file from a DataFrame needs an additional step, so practise first. Also, when you read in the data frame, you may need to change the delimiter to something else (for example, to change to a tab you have to add .option('delimiter','\\t')). You may also be asked to save using snappy compression, in which case you have to add .option('compression','snappy')."],"metadata":{}},{"cell_type":"code","source":["#Example read function:\nDF = spark.read.option(\"header\", \"false\").option(\"inferSchema\", \"true\").format(\"csv\").option('delimiter','\\t').load(\"problem3/data\")\n#Assuming you have predefined a schema (as in question 0 at the top):\nschema = some stuff\nDF = spark.read.option(\"header\", \"false\").option(\"inferSchema\", \"false\").format(\"csv\").option('delimiter','\\t').load(\"problem3/data\", schema = schema)\n\n#Example write function:\nDF.write.format('parquet').option('compression','snappy').save(\"problem3/soultion\")\n#Assuming you need to write an RDD to text:\nRDD.saveAsTextFile('problem3/solution')\n#Assuming you need to write a DF to text:\nI still need to figure this out. I got it wrong on the last attempt :/"],"metadata":{},"outputs":[],"execution_count":22}],"metadata":{"name":"PySpark_Training","notebookId":4519},"nbformat":4,"nbformat_minor":0}
